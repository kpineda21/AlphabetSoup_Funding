# AlphabetSoup_Funding

## Challenge 
- Two layers were tested, Layer 1 = 2000 and Layer 2 = 1500. Since the data set provided was so large, I decided that we needed the layers to also increase in size to get the most accurate results. Since it was such a large data set we sampled 5 Epochs. 
- We were able to achieve the target model performace. The test data results were: Loss: 0.03357564455789772, Accuracy: 0.9994168877601624
In order to recieve the most acurate reading we increased the batch size to obtain a wider sample. 
- Since it is such a large data set I would have tried using Big Data Analytics Tool. 
